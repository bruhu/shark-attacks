{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe952ab-18df-444e-812b-90833b4bbed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "shark_df = pd.read_excel('./shark-dataset.xls')\n",
    "# create dataframe copy\n",
    "original_df = shark_df.copy()\n",
    "shark_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1847c872-03ef-4dfa-9d3f-6b83fde3decc",
   "metadata": {},
   "source": [
    "Data cleaning to-do's:\n",
    "- (done) column names to lowercase\n",
    "- (done) column names - remove empty space after name\n",
    "- (done) column names - replace empty spaces with underscores\n",
    "- find unique values in columns\n",
    "- find duplicate rows\n",
    "- year names without floating\n",
    "- column 'Unnamed: 21' & 'Unnamed: 22' - what do we do with them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27d2263-6387-4a3c-b18c-d96343596dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names to lowercase, remove empty space in the end, replace empty spaces with underscore\n",
    "shark_df.columns = shark_df.columns.str.lower().str.strip().str.replace(\" \", \"_\")\n",
    "\n",
    "# remove multiple columns:\n",
    "shark_df = shark_df.drop(['type', 'state', 'name', 'species', 'source', 'pdf', 'href_formula', 'href', 'case_number', 'case_number.1', 'original_order', 'unnamed:_21', 'unnamed:_22', 'time'], axis=1)\n",
    "\n",
    "# convert year values to int\n",
    "# shark_df['year'] = shark_df['year'].apply(lambda x: int(x) if isinstance(x, float) else x)\n",
    "shark_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9859cbf-765e-4989-8d03-0e888445dc58",
   "metadata": {},
   "source": [
    "TUNG: YEARS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1bca00-f9dc-451a-a166-8c3b6d046299",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = shark_df\n",
    "\n",
    "# Filter the DataFrame because years date back to the birth of jesus christ, our lord and saviour. \n",
    "start_year = 2014\n",
    "end_year = 2024\n",
    "\n",
    "dft = shark_df[(shark_df[\"year\"] >= start_year) & (shark_df[\"year\"] <= end_year)]\n",
    "\n",
    "#convert float in year to int\n",
    "#this way doesn't convert into int, but error messages disappears, WHYYYY\n",
    "dft[\"year\"] = dft[\"year\"].fillna(0).astype(int)\n",
    "\n",
    "#this conversion works, however the stupid error message \n",
    "#year_filtered_dft[\"year\"] = year_filtered_dft[\"year\"].apply(lambda x : int(x))\n",
    "\n",
    "# showing that there are NO NaNs in date and year; \n",
    "print(dft.isnull().sum())\n",
    "print(\"\\nThe unique values in year are:\\n\", dft.year.unique())\n",
    "print(\"\\nThe datatype for column is currently:\\n\", dft.year.dtype)\n",
    "\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02f85a-866c-49e6-aed4-ce4a5de32e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "# Function to parse different date formats\n",
    "def parse_date(date_str):\n",
    "    if isinstance(date_str, str):\n",
    "        try: \n",
    "            return pd.to_datetime(date_str)  # Try direct conversion\n",
    "        except ValueError:\n",
    "            match = re.search(r'(\\d{4}-\\d{1,2}-\\d{1,2}|\\d{1,2}-[A-Za-z]{3}-\\d{4}|\\b[A-Za-z]{3}-\\d{4}\\b)', date_str)\n",
    "            if match:\n",
    "                date_str = match.group(0)\n",
    "                try:\n",
    "                    return datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        return datetime.strptime(date_str, \"%d-%b-%Y\")\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            return datetime.strptime(date_str, \"%b-%Y\")\n",
    "                        except ValueError:\n",
    "                            return None  # Return None for invalid formats\n",
    "    elif isinstance(date_str, datetime):\n",
    "        return date_str  # Return the datetime object as is\n",
    "    return None  # Return None if not a string or datetime\n",
    "\n",
    "# Create datetime_column and string_column\n",
    "dft[\"datetime_column\"] = dft[\"date\"].apply(parse_date)\n",
    "dft[\"string_column\"] = dft[\"date\"].apply(lambda x: x if isinstance(x, str) else None)\n",
    "\n",
    "# Drop rows with invalid datetime values\n",
    "dft = dft[dft[\"datetime_column\"].notna()]\n",
    "\n",
    "# Extract month and year from datetime_column\n",
    "dft['month'] = dft[\"datetime_column\"].apply(lambda x: x.month if pd.notnull(x) else None)\n",
    "dft['year'] = dft[\"datetime_column\"].apply(lambda x: x.year if pd.notnull(x) else None)\n",
    "#dft['month'] = dft[\"datetime_column\"].dt.month\n",
    "#dft['year'] = dft[\"datetime_column\"].dt.year\n",
    "\n",
    "# Define season mapping\n",
    "season_mapping = {\n",
    "    \"Spring\": [3, 4, 5],\n",
    "    \"Summer\": [6, 7, 8],\n",
    "    \"Autumn\": [9, 10, 11],\n",
    "    \"Winter\": [12, 1, 2]\n",
    "}\n",
    "\n",
    "# Function to assign season based on month\n",
    "def what_season(month):\n",
    "    for season, months in season_mapping.items():\n",
    "        if month in months:\n",
    "            return season\n",
    "    return None\n",
    "\n",
    "# Assign season based on the extracted month\n",
    "dft['season'] = dft['month'].apply(what_season)\n",
    "\n",
    "# Check the resulting DataFrame\n",
    "print(dft[['date', 'datetime_column', 'string_column', 'year', 'month', 'season']])\n",
    "\n",
    "count_of_spring = (dft[\"season\"] == \"Spring\").sum()\n",
    "print(count_of_spring)\n",
    "count_of_summer = (dft[\"season\"] == \"Summer\").sum()\n",
    "print(count_of_summer)\n",
    "count_of_autumn = (dft[\"season\"] == \"Autumn\").sum()\n",
    "print(count_of_autumn)\n",
    "count_of_winter = (dft[\"season\"] == \"Winter\").sum()\n",
    "print(count_of_winter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542f30e3-eb19-4afa-bdfd-d1f48a92733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "groups_by_seanson_and_injury = dft.groupby([\"season\", \"injury\"])\n",
    "groups_by_seanson_and_injury.get_group(\"Autumn\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127ad7a9",
   "metadata": {},
   "source": [
    "# Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d6e283-fea9-43fe-806d-852d29d169ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Johanna - country and location\n",
    "dfj = shark_df.copy()\n",
    "\n",
    "# unique countries\n",
    "dfj.country.unique() # many many countries (unsure values and very small countries)\n",
    "top_20_countries = dfj.country.value_counts().head(20)\n",
    "\n",
    "# stick to top 20 countries\n",
    "dfj = dfj[dfj.country.isin(top_20_countries.index)] # deletes around 1000 of originally 6900 rows\n",
    "\n",
    "# first letter in uppercase for all countries except USA for consistency\n",
    "dfj.country = dfj.country.apply(lambda x: x.title() if x != 'USA' else x)\n",
    "dfj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c21dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop location column\n",
    "dfj_USA = dfj[dfj.country.isin(['USA'])]\n",
    "dfj_USA.head()\n",
    "dfj_USA.location.unique() # too complicated --> stick to USA overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55548536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a62324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=top_20_countries.index.str.title(), y=top_20_countries.values, palette='viridis')\n",
    "plt.title('Top 20 countries of shark attacks')\n",
    "plt.xlabel('Country')\n",
    "plt.tick_params(axis='x', labelsize=9)\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b4343f-42e5-4300-9f63-7252bd5d0b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sex wrangling with Tung's years\n",
    "\n",
    "sex_df = dft.copy()\n",
    "\n",
    "sex_df['sex'] = sex_df['sex'].str.strip()\n",
    "\n",
    "# Replace specific values\n",
    "sex_df['sex'] = sex_df['sex'].replace({\n",
    "    'M': 'M', \n",
    "    'F': 'F',  \n",
    "    'N': np.nan,  \n",
    "    'M x 2': 'M', \n",
    "    'lli': np.nan,  \n",
    "    '.': np.nan,  \n",
    "    ' M': 'M'  \n",
    "})\n",
    "\n",
    "sex_df['sex']= sex_df['sex'].fillna('unknown')\n",
    "\n",
    "#Calculate the counts of \"M\" and \"F\"\n",
    "total_known = sex_df['sex'].value_counts()\n",
    "m_count = total_known.get('M', 0)\n",
    "f_count = total_known.get('F', 0)\n",
    "total = m_count + f_count\n",
    "\n",
    "#Calculate the percentages of \"M\" and \"F\"\n",
    "if total > 0:\n",
    "    m_percentage = m_count / total\n",
    "    f_percentage = f_count / total\n",
    "else:\n",
    "    m_percentage = 0.5  # Default to equal distribution if no known values\n",
    "    f_percentage = 0.5\n",
    "\n",
    "# Determine the number of \"Unknown\" values\n",
    "unknown_count = sex_df['sex'].value_counts().get('unknown', 0)\n",
    "\n",
    "# Calculate how many \"Unknown\" values to fill with \"M\" and \"F\"\n",
    "m_fill_count = int(m_percentage * unknown_count)\n",
    "f_fill_count = unknown_count - m_fill_count  # Ensure all \"Unknown\" are assigned\n",
    "\n",
    "# Get indices of the \"Unknown\" entries\n",
    "unknown_indices = sex_df[sex_df['sex'] == 'unknown'].index\n",
    "\n",
    "# Randomly shuffle the \"Unknown\" indices\n",
    "shuffled_indices = np.random.permutation(unknown_indices)\n",
    "\n",
    "# Split the shuffled indices into two groups for \"M\" and \"F\"\n",
    "m_indices = shuffled_indices[:m_fill_count]\n",
    "f_indices = shuffled_indices[m_fill_count:]\n",
    "\n",
    "# Assign \"M\" and \"F\" to the split indices\n",
    "sex_df.loc[m_indices, 'sex'] = 'M'\n",
    "sex_df.loc[f_indices, 'sex'] = 'F'\n",
    "\n",
    "# Verify replacements by checking updated counts\n",
    "print(sex_df['sex'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f4b175-ee8c-4af1-b8fd-78b6629c828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#age wrangling with Tung's years\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "age_df = dft.copy()\n",
    "\n",
    "def convert_descriptive_age(value):\n",
    "    if pd.isnull(value):\n",
    "        return np.nan\n",
    "    value = str(value).strip().lower()\n",
    "    if value in [\"teen\", \"teens\"]:\n",
    "        return 15  # Approximate age for teenagers\n",
    "    elif value == \"adult\":\n",
    "        return 30  # General average for adult age\n",
    "    elif value in [\"middle age\", '\"middle-age\"']:\n",
    "        return 45  # Approximate age for middle age\n",
    "    elif value == \"elderly\":\n",
    "        return 70  # Approximate age for elderly\n",
    "    elif value in [\"a minor\", \"young\"]:\n",
    "        return 10  # Assume a minor is around 10 years old\n",
    "    elif value == \"infant\" or value == \"9 months\" or value == \"2 to 3 months\":\n",
    "        return 1  # Age 1 for infants\n",
    "    elif \"month\" in value:\n",
    "        return 1  # Treat other month values as infants\n",
    "    return value\n",
    "\n",
    "age_df['age'] = age_df['age'].apply(convert_descriptive_age)\n",
    "\n",
    "def convert_to_first_age(value):\n",
    "    if isinstance(value, str):\n",
    "        numbers = re.findall(r'\\d+', value)\n",
    "        if numbers:\n",
    "            return int(numbers[0])  \n",
    "    return value\n",
    "\n",
    "age_df['age'] = age_df['age'].apply(convert_to_first_age)\n",
    "\n",
    "def convert_half_age(value):\n",
    "    if isinstance(value, str) and \"½\" in value:\n",
    "        # Replace \"½\" with \".5\" and convert to float\n",
    "        return float(value.replace(\"½\", \".5\"))\n",
    "    return value  \n",
    "\n",
    "age_df['age'] = age_df['age'].apply(convert_half_age)\n",
    "\n",
    "\n",
    "#Convert any remaining irregular entries to NaN\n",
    "def convert_irregular_entries(value):\n",
    "    if isinstance(value, str) and not any(char.isdigit() for char in value):\n",
    "        return np.nan  \n",
    "    return value\n",
    "\n",
    "age_df['age'] = age_df['age'].apply(convert_irregular_entries)\n",
    "\n",
    "#convert to numeric\n",
    "age_df['age'] = pd.to_numeric(age_df['age'], errors='coerce')\n",
    "\n",
    "#Replace NaN values with the mode of the age column\n",
    "age_mode = age_df['age'].mode()[0]\n",
    "age_df['age'] = age_df['age'].fillna(age_mode)\n",
    "\n",
    "#convert type to int\n",
    "age_df['age'] = age_df['age'].astype(int)\n",
    "\n",
    "# Show all unique values in the 'age' column, including NaN counts\n",
    "unique_values_age = age_df['age'].value_counts(dropna=False)\n",
    "print(f\"Unique values after cleaning:\\n{unique_values_age}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980d07f3-2175-44fb-a309-ea2968fc9a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "gender_counts = sex_df['sex'].value_counts()\n",
    "print(gender_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec8d7f6-44f1-4be6-a631-1c35660295e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='sex', data=sex_df, order=gender_counts.index)\n",
    "plt.title('Shark Attacks by Gender')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Number of Attacks')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0036424-a70c-4d6e-b065-edcaa800e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_bins = list(range(0, 101, 10))  # creates [0, 10, 20, ..., 100]\n",
    "age_labels = [f\"{age_bins[i]}-{age_bins[i+1] - 1}\" for i in range(len(age_bins) - 1)]\n",
    "\n",
    "# Apply pd.cut with the new bins and labels\n",
    "age_df['age_group'] = pd.cut(age_df['age'], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "# Calculate and display age group counts\n",
    "age_group_counts = age_df['age_group'].value_counts().sort_index()\n",
    "print(age_group_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0820460-c043-4e65-8ff3-405823a53945",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='age_group', data=age_df, order=age_group_counts.index)\n",
    "plt.title('Shark Attacks by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Number of Attacks')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5102456b-3d45-430a-bd8e-650ec72e5486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bru - fatality wrangling\n",
    "\n",
    "#copy df for safety reasons\n",
    "bru_df = shark_df.copy()\n",
    "\n",
    "# rename column\n",
    "bru_df.rename(columns={'unnamed:_11': 'fatal'}, inplace=True)\n",
    "\n",
    "# check unique values\n",
    "unique_values_fatal = bru_df['fatal'].unique()\n",
    "print(f\"Unique values before cleaning: {unique_values_fatal}\")\n",
    "\n",
    "# replace values\n",
    "bru_df['fatal'] = bru_df['fatal'].replace({'N':'no','Y':'yes','n':'no','Y x 2':'yes',' N':'no','N ':'no','y':'yes','UNKNOWN':'unknown'})\n",
    "\n",
    "# remove rows with specific values\n",
    "rows_to_remove = ['Nq', 'M', 'F', 2017]\n",
    "bru_df = bru_df[~bru_df['fatal'].isin(rows_to_remove)]\n",
    "\n",
    "#drop rows with NaN values\n",
    "bru_df = bru_df.dropna(subset=['fatal'])\n",
    "\n",
    "# check again\n",
    "unique_values_fatal = bru_df['fatal'].unique()\n",
    "print(f\"Unique values after cleaning: {unique_values_fatal}\")\n",
    "\n",
    "# print(bru_df.describe())\n",
    "print(bru_df.groupby('fatal').count())\n",
    "\n",
    "fatality_counts = bru_df['fatal'].value_counts()\n",
    "print(\"fatality counts\", fatality_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfd8fbb-ae9a-43ca-be07-e2e503145b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fatality wrangling with tung's dataframe (2014 to 2024)\n",
    "\n",
    "import numpy as np\n",
    "# copy of tung's df\n",
    "fatal_df = dft.copy()\n",
    "\n",
    "# rename column\n",
    "fatal_df.rename(columns={'unnamed:_11': 'fatal'}, inplace=True)\n",
    "\n",
    "replacement_dict = {\n",
    "    'N': 'no',\n",
    "    'Y': 'yes',\n",
    "    'M': 'unknown',\n",
    "    'F': 'unknown',\n",
    "    'n': 'no',\n",
    "    'Nq': 'unknown'\n",
    "}\n",
    "\n",
    "#fill NaN vals with 'unknown' and replace unique values\n",
    "fatal_df['fatal'] = fatal_df['fatal'].fillna('unknown').replace(replacement_dict)\n",
    "\n",
    "fatality_counts = fatal_df['fatal'].value_counts()\n",
    "display(\"fatality counts\", fatality_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9047b21-de74-4080-9a95-b81921030d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bru - activity wrangling\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# check unique values\n",
    "unique_values_activity = bru_df['activity'].unique()\n",
    "# print(unique_values_activity)\n",
    "\n",
    "# convert all values to a common case\n",
    "bru_df['activity'] = bru_df['activity'].str.strip().str.lower().str.replace(r\"[\\\"']\", '', regex=True)\n",
    "\n",
    "'''\n",
    "The word_count() function uses collections and re to concatenate all the values in the column to a single string.\n",
    "Then it will split the combined string into individual words.\n",
    "Using Counters, it will return the frequency of each word.\n",
    "It will also store the top 10 most common words in a list\n",
    "'''\n",
    "\n",
    "most_common_words = []\n",
    "\n",
    "def word_count():\n",
    "    bru_df['activity'] = bru_df['activity'].fillna('').astype(str) # replace NaN values with an empty string and convert all to string\n",
    "    all_text = ' '.join(bru_df['activity']) # combine all values into a single string\n",
    "    words = re.findall(r'\\w+', all_text.lower()) # split into words (regex to handle punctuation)\n",
    "    word_counts = Counter(words) # count word frequency\n",
    "    most_common_words = [word for word, count in word_counts.most_common(50) if len(word) >= 5]\n",
    "    return most_common_words\n",
    "    return word_count\n",
    "\n",
    "word_count()\n",
    "most_common_words = word_count()\n",
    "\n",
    "#print(\"Most common words\")\n",
    "#print(most_common_words)\n",
    "\n",
    "print('Top values before replacement function\\n', bru_df['activity'].value_counts().head(10))\n",
    "#manually entered seoelcted values\n",
    "selected_values_to_replace = ['surfing', 'diving', 'fishing', 'swimming', 'wading', 'bathing', 'snorkeling', 'kayaking', 'body boarding', 'scuba diving']\n",
    "\n",
    "\n",
    "def replace_values():\n",
    "    for word_to_replace in selected_values_to_replace:\n",
    "        bru_df.loc[bru_df['activity'].str.contains(word_to_replace, case=False, na=False), 'activity'] = word_to_replace\n",
    "\n",
    "    return bru_df\n",
    "\n",
    "updated_bru_df = replace_values()\n",
    "\n",
    "print('\\nTop values after replacement:\\n', updated_bru_df['activity'].value_counts().head(10))\n",
    "\n",
    "# print(\"Word count:\")\n",
    "# print(word_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee3736d-b85d-40b0-8577-e3ae97134117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# playing with visual representation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Count top 10 values in the 'activity' column\n",
    "top_values = updated_bru_df['activity'].str.capitalize().value_counts().head(10)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=top_values.index, y=top_values.values, palette='viridis')\n",
    "plt.title('Top 10 activities that may result in shark attacks')\n",
    "plt.xlabel('Activity')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d433dec9-8c05-4dc9-a863-7be989b3dec6",
   "metadata": {},
   "source": [
    "### Columns we need in the project\n",
    "- Years\n",
    "- date (months?)\n",
    "- activity (can we stand on a beach?)\n",
    "- country/state/location -> do we need all? let's start with country + location and see how messy it gets from then on?\n",
    "- age - hospital costs might change\n",
    "- sex\n",
    "- unnamed 11 (fatal or not) yes for fatal\n",
    "- injury (how does that combine with activity type?)\n",
    "- Jonathan adds column with organs lost\n",
    "\n",
    "### Formula\n",
    "probably looks like : who are you, where are you, what are you going to do and when? -> probability calculated through that (will it be fatal or not), and then the result can be checked into the three insurance categories\n",
    "\n",
    "- location is going to be an important parameter here (another correlation to definitely check, big influential factor?)\n",
    "\n",
    "- !POINT SYSTEM!\n",
    "\n",
    "- add point system for column unique values (genius)\n",
    "\n",
    "### Other parameters to take into account:\n",
    "- comparison between years to calculate potential drama in upcoming years\n",
    "- calculate probability based on different parameters\n",
    "- we're g etting creepy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8fdf9-d2dc-4b6f-87fe-3de251efea1d",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "1. Select columns we will use\n",
    "2. Inspect column data, see where we have null or empty values\n",
    "3. Decide what to do with the above\n",
    "4. 'homogenize' column values\n",
    "5. Figure out calculations for probability. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
