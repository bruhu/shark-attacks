{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8137c82c-8ffe-4329-8663-597aeb6ce13e",
   "metadata": {},
   "source": [
    "# Imports\n",
    "- All library imports\n",
    "- Original DataFrame import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0546618e-4156-431b-9b36-c503bf98a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "shark_df = pd.read_excel('../shark-dataset.xls')\n",
    "shark_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f89f81-825c-4838-a2b6-756f9d887877",
   "metadata": {},
   "source": [
    "### Column cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1979d068-e657-4105-b3a9-057f58c5baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_columns = ['type', 'state', 'name', 'location', 'species', 'source', 'pdf', 'href_formula', 'href', 'case_number', 'case_number.1', 'original_order', 'unnamed:_21', 'unnamed:_22', 'time', 'injury']\n",
    "\n",
    "def clean_columns(df):\n",
    "    df.columns = df.columns.str.lower().str.strip().str.replace(\" \", \"_\", regex=False) # lowercase col names, remove+replace empty spaces\n",
    "    df.rename(columns={'unnamed:_11': 'fatal'}, inplace=True)\n",
    "    df = df.drop(unused_columns, axis=1, errors='ignore')\n",
    "    return df\n",
    "\n",
    "shark_df = clean_columns(shark_df)\n",
    "shark_df.tail(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6b766d-a520-4b7d-b61e-7550226f050a",
   "metadata": {},
   "source": [
    "### Country formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebe7cc5-4b82-4821-8b6a-d7187819a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # capitalize names in 'country' except for 'USA', handle two-word countries\n",
    "# def country_formatting(df):\n",
    "#     df['country'] = df['country'].apply(lambda x: \n",
    "#     ' '.join(word.capitalize() for word in x.split()) if x.lower() != 'usa' else x)\n",
    "#     return df\n",
    "\n",
    "# shark_df = country_formatting(shark_df)\n",
    "# shark_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0238a40-20a4-44cb-a314-57759e836b63",
   "metadata": {},
   "source": [
    "### Year filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d74206-2687-4aec-bbf5-a97abf38541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 2014\n",
    "end_year = 2024\n",
    "\n",
    "def filter_years(df):\n",
    "    df = df[(df['year'] >= start_year) & (shark_df['year'] <= end_year)]\n",
    "    df['year'] = df['year'].fillna(0).astype(int) #convert float in year to int\n",
    "    return df\n",
    "\n",
    "shark_df = clean_columns(shark_df)\n",
    "shark_df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273833e0-1714-49f2-9519-9cfb111a2334",
   "metadata": {},
   "source": [
    "## Years (Tung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42edd4ee-93e7-4381-aa04-02ad8f6aa9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce range rows for better valid inputs\n",
    "\n",
    "start_year = 2014\n",
    "end_year = 2024\n",
    "\n",
    "shark_df = shark_df[(shark_df[\"year\"] >= start_year) & (shark_df[\"year\"] <= end_year)]\n",
    "\n",
    "#convert float in year to int\n",
    "shark_df[\"year\"] = shark_df[\"year\"].fillna(0).astype(int)\n",
    "\n",
    "# remove invalid rows with \"2014\" as date\n",
    "shark_df = shark_df.drop(shark_df.index[-2:])\n",
    "\n",
    "\n",
    "total_count_spring = 298\n",
    "total_count_summer = 405\n",
    "total_count_autumn = 290\n",
    "total_count_winter = 231\n",
    "\n",
    "shark_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8211cf-f251-4a75-b381-4d56064487b7",
   "metadata": {},
   "source": [
    "## Date & Time (Tung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f44c871-9396-480b-90ae-f29879a92bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse different date formats\n",
    "def parse_date(date_str):\n",
    "    if isinstance(date_str, str):\n",
    "        try: \n",
    "            return pd.to_datetime(date_str)  # Try direct conversion\n",
    "        except ValueError:\n",
    "            match = re.search(r'(\\d{4}-\\d{1,2}-\\d{1,2}|\\d{1,2}-[A-Za-z]{3}-\\d{4}|\\b[A-Za-z]{3}-\\d{4}\\b)', date_str)\n",
    "            if match:\n",
    "                date_str = match.group(0)\n",
    "                try:\n",
    "                    return datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        return datetime.strptime(date_str, \"%d-%b-%Y\")\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            return datetime.strptime(date_str, \"%b-%Y\")\n",
    "                        except ValueError:\n",
    "                            return None  # Return None for invalid formats\n",
    "    elif isinstance(date_str, datetime):\n",
    "        return date_str  # Return the datetime object as is\n",
    "    return None  # Return None if not a string or datetime\n",
    "\n",
    "# Create datetime_column and string_column\n",
    "shark_df[\"datetime_column\"] = shark_df[\"date\"].apply(parse_date)\n",
    "shark_df[\"string_column\"] = shark_df[\"date\"].apply(lambda x: x if isinstance(x, str) else None)\n",
    "\n",
    "# Drop rows with invalid datetime values\n",
    "shark_df = shark_df[shark_df[\"datetime_column\"].notna()]\n",
    "\n",
    "# Extract month and year from datetime_column\n",
    "shark_df['month'] = shark_df[\"datetime_column\"].apply(lambda x: x.month if pd.notnull(x) else None)\n",
    "shark_df['year'] = shark_df[\"datetime_column\"].apply(lambda x: x.year if pd.notnull(x) else None)\n",
    "#shark_df['month'] = shark_df[\"datetime_column\"].dt.month\n",
    "#shark_df['year'] = shark_df[\"datetime_column\"].dt.year\n",
    "\n",
    "# Define season mapping\n",
    "season_mapping = {\n",
    "    \"Spring\": [3, 4, 5],\n",
    "    \"Summer\": [6, 7, 8],\n",
    "    \"Autumn\": [9, 10, 11],\n",
    "    \"Winter\": [12, 1, 2]\n",
    "}\n",
    "\n",
    "# Function to assign season based on month\n",
    "def what_season(month):\n",
    "    for season, months in season_mapping.items():\n",
    "        if month in months:\n",
    "            return season\n",
    "    return None\n",
    "\n",
    "# Assign season based on the extracted month\n",
    "shark_df['season'] = shark_df['month'].apply(what_season)\n",
    "\n",
    "# Check the resulting DataFrame\n",
    "print(shark_df[['date', 'datetime_column', 'string_column', 'year', 'month', 'season']])\n",
    "shark_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233f5498-7864-46ea-8a98-1c9ab2f79919",
   "metadata": {},
   "source": [
    "## Fatality rates (Bru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864a025d-2fec-48f1-8326-6c8558d6aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column\n",
    "shark_df.rename(columns={'unnamed:_11': 'fatal'}, inplace=True)\n",
    "\n",
    "replacement_dict = {\n",
    "    'N': 'no',\n",
    "    'Y': 'yes',\n",
    "    'M': 'unknown',\n",
    "    'F': 'unknown',\n",
    "    'n': 'no',\n",
    "    'Nq': 'unknown'\n",
    "}\n",
    "\n",
    "#fill NaN vals with 'unknown' and replace unique values\n",
    "shark_df['fatal'] = shark_df['fatal'].fillna('unknown').replace(replacement_dict)\n",
    "\n",
    "fatality_counts = shark_df['fatal'].value_counts()\n",
    "display(\"fatality counts\", fatality_counts)\n",
    "\n",
    "shark_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a9a8c2-5c9c-495b-b3f8-fbfd1d0922eb",
   "metadata": {},
   "source": [
    "## Activity (Bru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cb0912-0963-4520-b918-f9617d72b419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values\n",
    "unique_values_activity = shark_df['activity'].unique()\n",
    "# print(unique_values_activity)\n",
    "\n",
    "# Convert all values to a common case\n",
    "shark_df['activity'] = shark_df['activity'].str.strip().str.lower().str.replace(r\"[\\\"']\", '', regex=True)\n",
    "\n",
    "most_common_words = []\n",
    "\n",
    "def word_count():\n",
    "    global most_common_words  # Declare the global variable\n",
    "    shark_df['activity'] = shark_df['activity'].fillna('').astype(str)  # replace NaN values with an empty string\n",
    "    all_text = ' '.join(shark_df['activity'])  # combine all values into a single string\n",
    "    words = re.findall(r'\\w+', all_text.lower())  # split into words\n",
    "    word_counts = Counter(words)  # count word frequency\n",
    "    most_common_words = [word for word, count in word_counts.most_common(50) if len(word) >= 5]\n",
    "    return most_common_words\n",
    "\n",
    "# Call the function to get most common words\n",
    "most_common_words = word_count()\n",
    "\n",
    "print('Top values before replacement function\\n', shark_df['activity'].value_counts().head(10))\n",
    "\n",
    "# Manually entered selected values\n",
    "selected_values_to_replace = ['surfing', 'diving', 'fishing', 'swimming', 'wading', 'bathing', 'snorkeling', 'kayaking', 'body boarding', 'scuba diving']\n",
    "\n",
    "def replace_values(shark_df, selected_values_to_replace):\n",
    "    for word_to_replace in selected_values_to_replace:\n",
    "        shark_df.loc[shark_df['activity'].str.contains(word_to_replace, case=False, na=False), 'activity'] = word_to_replace\n",
    "    return shark_df\n",
    "\n",
    "# Replace values\n",
    "shark_df = replace_values(shark_df, selected_values_to_replace)\n",
    "\n",
    "# Assuming you want to filter based on the most common activities\n",
    "top_10_activities = shark_df['activity'].value_counts().head(10).index  # Get top activities\n",
    "\n",
    "# Filter shark_df based on top 10 activities\n",
    "shark_df = shark_df[shark_df['activity'].isin(top_10_activities)]\n",
    "\n",
    "# Display results\n",
    "print(\"Top values after replacement:\\n\", shark_df['activity'].value_counts().head(10))\n",
    "print(\"Filtered DataFrame:\\n\", shark_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98118b9-b7e6-4698-82eb-f7e05dfaea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_df['sex'] = shark_df['sex'].str.strip()\n",
    "\n",
    "# Replace specific values\n",
    "shark_df['sex'] = shark_df['sex'].replace({\n",
    "    'M': 'M', \n",
    "    'F': 'F',  \n",
    "    'N': np.nan,  \n",
    "    'M x 2': 'M', \n",
    "    'lli': np.nan,  \n",
    "    '.': np.nan,  \n",
    "    ' M': 'M'  \n",
    "})\n",
    "\n",
    "shark_df['sex']= shark_df['sex'].fillna('unknown')\n",
    "\n",
    "#Calculate the counts of \"M\" and \"F\"\n",
    "total_known = shark_df['sex'].value_counts()\n",
    "m_count = total_known.get('M', 0)\n",
    "f_count = total_known.get('F', 0)\n",
    "total = m_count + f_count\n",
    "\n",
    "#Calculate the percentages of \"M\" and \"F\"\n",
    "if total > 0:\n",
    "    m_percentage = m_count / total\n",
    "    f_percentage = f_count / total\n",
    "else:\n",
    "    m_percentage = 0.5  # Default to equal distribution if no known values\n",
    "    f_percentage = 0.5\n",
    "\n",
    "# Determine the number of \"Unknown\" values\n",
    "unknown_count = shark_df['sex'].value_counts().get('unknown', 0)\n",
    "\n",
    "# Calculate how many \"Unknown\" values to fill with \"M\" and \"F\"\n",
    "m_fill_count = int(m_percentage * unknown_count)\n",
    "f_fill_count = unknown_count - m_fill_count  # Ensure all \"Unknown\" are assigned\n",
    "\n",
    "# Get indices of the \"Unknown\" entries\n",
    "unknown_indices = shark_df[shark_df['sex'] == 'unknown'].index\n",
    "\n",
    "# Randomly shuffle the \"Unknown\" indices\n",
    "shuffled_indices = np.random.permutation(unknown_indices)\n",
    "\n",
    "# Split the shuffled indices into two groups for \"M\" and \"F\"\n",
    "m_indices = shuffled_indices[:m_fill_count]\n",
    "f_indices = shuffled_indices[m_fill_count:]\n",
    "\n",
    "# Assign \"M\" and \"F\" to the split indices\n",
    "shark_df.loc[m_indices, 'sex'] = 'M'\n",
    "shark_df.loc[f_indices, 'sex'] = 'F'\n",
    "\n",
    "# Verify replacements by checking updated counts\n",
    "print(shark_df['sex'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa24d600-80f8-4812-9eb8-c38c7463de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_descriptive_age(value):\n",
    "    if pd.isnull(value):\n",
    "        return np.nan\n",
    "    value = str(value).strip().lower()\n",
    "    if value in [\"teen\", \"teens\"]:\n",
    "        return 15  # Approximate age for teenagers\n",
    "    elif value == \"adult\":\n",
    "        return 30  # General average for adult age\n",
    "    elif value in [\"middle age\", '\"middle-age\"']:\n",
    "        return 45  # Approximate age for middle age\n",
    "    elif value == \"elderly\":\n",
    "        return 70  # Approximate age for elderly\n",
    "    elif value in [\"a minor\", \"young\"]:\n",
    "        return 10  # Assume a minor is around 10 years old\n",
    "    elif value == \"infant\" or value == \"9 months\" or value == \"2 to 3 months\":\n",
    "        return 1  # Age 1 for infants\n",
    "    elif \"month\" in value:\n",
    "        return 1  # Treat other month values as infants\n",
    "    return value\n",
    "\n",
    "shark_df['age'] = shark_df['age'].apply(convert_descriptive_age)\n",
    "\n",
    "def convert_to_first_age(value):\n",
    "    if isinstance(value, str):\n",
    "        numbers = re.findall(r'\\d+', value)\n",
    "        if numbers:\n",
    "            return int(numbers[0])  \n",
    "    return value\n",
    "\n",
    "shark_df['age'] = shark_df['age'].apply(convert_to_first_age)\n",
    "\n",
    "def convert_half_age(value):\n",
    "    if isinstance(value, str) and \"½\" in value:\n",
    "        # Replace \"½\" with \".5\" and convert to float\n",
    "        return float(value.replace(\"½\", \".5\"))\n",
    "    return value  \n",
    "\n",
    "shark_df['age'] = shark_df['age'].apply(convert_half_age)\n",
    "\n",
    "\n",
    "#Convert any remaining irregular entries to NaN\n",
    "def convert_irregular_entries(value):\n",
    "    if isinstance(value, str) and not any(char.isdigit() for char in value):\n",
    "        return np.nan  \n",
    "    return value\n",
    "\n",
    "shark_df['age'] = shark_df['age'].apply(convert_irregular_entries)\n",
    "\n",
    "#convert to numeric\n",
    "shark_df['age'] = pd.to_numeric(shark_df['age'], errors='coerce')\n",
    "\n",
    "#Replace NaN values with the mode of the age column\n",
    "age_mode = shark_df['age'].mode()[0]\n",
    "shark_df['age'] = shark_df['age'].fillna(age_mode)\n",
    "\n",
    "#convert type to int\n",
    "shark_df['age'] = shark_df['age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d6cb9e-d299-4171-89e5-d2c9d961f6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_df.rename(columns={'unnamed:_11': 'fatal'}, inplace=True)\n",
    "\n",
    "replacement_dict = {\n",
    "    'N': 'no',\n",
    "    'Y': 'yes',\n",
    "    'M': 'unknown',\n",
    "    'F': 'unknown',\n",
    "    'n': 'no',\n",
    "    'Nq': 'unknown'\n",
    "}\n",
    "\n",
    "#fill NaN vals with 'unknown' and replace unique values\n",
    "shark_df['fatal'] = shark_df['fatal'].fillna('unknown').replace(replacement_dict)\n",
    "\n",
    "fatality_counts = shark_df['fatal'].value_counts()\n",
    "display(\"fatality counts\", fatality_counts)\n",
    "\n",
    "shark_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae9eeb-39d9-429c-9120-c199fa40349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse different date formats\n",
    "def parse_date(date_str):\n",
    "    if isinstance(date_str, str):\n",
    "        try: \n",
    "            return pd.to_datetime(date_str)  # Try direct conversion\n",
    "        except ValueError:\n",
    "            match = re.search(r'(\\d{4}-\\d{1,2}-\\d{1,2}|\\d{1,2}-[A-Za-z]{3}-\\d{4}|\\b[A-Za-z]{3}-\\d{4}\\b)', date_str)\n",
    "            if match:\n",
    "                date_str = match.group(0)\n",
    "                try:\n",
    "                    return datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        return datetime.strptime(date_str, \"%d-%b-%Y\")\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            return datetime.strptime(date_str, \"%b-%Y\")\n",
    "                        except ValueError:\n",
    "                            return None  # Return None for invalid formats\n",
    "    elif isinstance(date_str, datetime):\n",
    "        return date_str  # Return the datetime object as is\n",
    "    return None  # Return None if not a string or datetime\n",
    "\n",
    "# Create datetime_column and string_column\n",
    "shark_df[\"datetime_column\"] = shark_df[\"date\"].apply(parse_date)\n",
    "shark_df[\"string_column\"] = shark_df[\"date\"].apply(lambda x: x if isinstance(x, str) else None)\n",
    "\n",
    "# Drop rows with invalid datetime values\n",
    "shark_df = shark_df[shark_df[\"datetime_column\"].notna()]\n",
    "\n",
    "# Extract month and year from datetime_column\n",
    "shark_df['month'] = shark_df[\"datetime_column\"].apply(lambda x: x.month if pd.notnull(x) else None)\n",
    "shark_df['year'] = shark_df[\"datetime_column\"].apply(lambda x: x.year if pd.notnull(x) else None)\n",
    "#shark_df['month'] = shark_df[\"datetime_column\"].dt.month\n",
    "#shark_df['year'] = shark_df[\"datetime_column\"].dt.year\n",
    "\n",
    "# Define season mapping\n",
    "season_mapping = {\n",
    "    \"Spring\": [3, 4, 5],\n",
    "    \"Summer\": [6, 7, 8],\n",
    "    \"Autumn\": [9, 10, 11],\n",
    "    \"Winter\": [12, 1, 2]\n",
    "}\n",
    "\n",
    "# Function to assign season based on month\n",
    "def what_season(month):\n",
    "    for season, months in season_mapping.items():\n",
    "        if month in months:\n",
    "            return season\n",
    "    return None\n",
    "\n",
    "# Assign season based on the extracted month\n",
    "shark_df['season'] = shark_df['month'].apply(what_season)\n",
    "\n",
    "# Check the resulting DataFrame\n",
    "print(shark_df[['date', 'datetime_column', 'string_column', 'year', 'month', 'season']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de62e91e-b6f9-4af0-8574-51dfaac1d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b8dc1-ec95-4ce6-8897-2b5bc7d94ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter based on the most common countries\n",
    "top_10_countries = shark_df['country'].value_counts().head(10).index  # Get top activities\n",
    "\n",
    "# filter shark_df based on top 10 countries\n",
    "shark_df = shark_df[shark_df['country'].isin(top_10_countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eed2f6-3e8e-46de-84db-9a2957917d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capitalize names in 'country' except for 'usa' and handle two-word countries\n",
    "shark_df['country'] = shark_df['country'].apply(lambda x: \n",
    "    ' '.join(word.capitalize() for word in x.split()) if x.lower() != 'usa' else x)\n",
    "\n",
    "print(shark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c108ea5a-66ff-4249-b690-41a8294ed412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to remove\n",
    "columns_to_remove = ['date', 'datetime_column', 'string_column', 'month']\n",
    "\n",
    "# Remove the specified columns\n",
    "shark_df = shark_df.drop(columns=columns_to_remove)\n",
    "\n",
    "print(shark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f928ad-41c6-498d-ba25-fc8c93b8e21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70823581-dfe0-4c14-87b3-4b0e012dfdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty values in column 'activity'\n",
    "shark_df = shark_df[shark_df['activity'].notna()]\n",
    "shark_df = shark_df[shark_df['activity'].str.strip().ne('')]\n",
    "shark_df = shark_df[shark_df['activity'].str.strip() != '']\n",
    "\n",
    "\n",
    "print(shark_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2c5e7c-11d4-45cd-9142-d8215dd5a4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_final_df = shark_df.to_csv('shark_final_df.csv', index=False)\n",
    "shark_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9851294-c59f-42c9-89b1-0608f6e51bea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
